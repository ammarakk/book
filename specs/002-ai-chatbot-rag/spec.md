# Feature Specification: Phase 2 – Embedded AI Chatbot for Physical AI & Humanoid Robotics Book

**Feature Branch**: `002-ai-chatbot-rag`
**Created**: 2025-01-04
**Status**: Draft
**Input**: User description: "/sp.specify Phase 2 – AI Chatbot (RAG System) Phase Name: Phase 2 – Embedded AI Chatbot for Physical AI & Humanoid Robotics Book Objective: Design and specify an embedded Retrieval-Augmented Generation (RAG) chatbot that answers user questions strictly from the book content. The chatbot must integrate seamlessly into the Docusaurus UI and follow all constitution constraints. This phase focuses ONLY on chatbot intelligence and retrieval. No authentication, personalization, or translation is allowed. -------------------------------------------------- SCOPE (IN-SCOPE ONLY) -------------------------------------------------- 1. Chatbot Capabilities - Embedded chatbot UI inside the book - Floating chatbot icon (robot-themed, animated) - Context-aware responses based on book content - Answers must be grounded in retrieved documents - Ability to answer questions using: - Entire book context - User-selected text only (strict mode) 2. RAG Architecture - Vector-based retrieval using Qdrant Cloud (Free Tier) - Metadata storage using Neon Serverless PostgreSQL - Backend API using FastAPI - Chunking and embedding of book content - Deterministic retrieval + generation pipeline 3. LLM Configuration - LLM Provider: Ollama (local or server-hosted) - Supported models must be explicitly defined in config - No OpenAI, Gemini, or Claude API usage for inference - Claude Code allowed ONLY as orchestration/spec tool 4. UI / UX Requirements - Chatbot icon must be: - Robot-themed - Animated (hover / idle animation) - Chat panel must: - Open as overlay or side panel - Not disrupt reading experience - Visual style must match: - Neon robotic theme - Phase 1 UI consistency 5. Context Control - Two chat modes: 1. Global Mode – uses full indexed book 2. Selection Mode – answers ONLY from selected text - Selection mode must hard-fail if answer is not found -------------------------------------------------- OUT OF SCOPE (STRICT) -------------------------------------------------- - User authentication - Signup / Signin - Personalization - Translation - User memory - Analytics - Model fine-tuning - Deployment automation -------------------------------------------------- TECH STACK (LOCKED) -------------------------------------------------- Frontend: - Docusaurus - React - CSS / Framer Motion (animations) Backend: - FastAPI - REST API only (no WebSockets in this phase) Databases: - Qdrant Cloud (vector store) - Neon Serverless PostgreSQL (metadata, document refs) AI: - Ollama (LLM runtime) - Embedding model compatible with Ollama - Claude Code Subagents NOT allowed in runtime -------------------------------------------------- DATA FLOW (MANDATORY) -------------------------------------------------- 1. Book Content - Markdown files parsed - Chunked deterministically - Embedded and stored in Qdrant - Metadata stored in Neon 2. User Query - Query received from UI - Context mode determined (global or selection) - Relevant chunks retrieved from Qdrant - Prompt assembled with strict grounding rules - Answer generated by Ollama - Response returned to UI -------------------------------------------------- SECURITY & RULES -------------------------------------------------- - No hallucinations allowed - If answer not found → respond with: "This information is not available in the book." - No external web access - No cross-phase feature leakage - API keys must be loaded via environment variables -------------------------------------------------- SUCCESS CRITERIA -------------------------------------------------- Phase 2 is successful when: - Chatbot is visible and usable inside the book - Answers come only from indexed book content - Selection-only answering works correctly - UI animations function smoothly - Backend RAG pipeline is stable - Phase passes verification and is locked -------------------------------------------------- DELIVERABLES -------------------------------------------------- - Chatbot UI component - FastAPI RAG backend - Qdrant vector index - Neon metadata schema - Environment variable template - Verification checklist -------------------------------------------------- PHASE EXIT RULE -------------------------------------------------- Phase 2 is locked ONLY after: - Manual verification passes - No constitution violations - No Phase 3 features present -------------------------------------------------- FINAL NOTE -------------------------------------------------- This specification defines WHAT must be built. Planning defines HOW it will be built. Implementation executes ONLY this scope. Any deviation must be rejected."

## Constitution Compliance Check

### Phase Isolation Check
- [X] This feature belongs to the current phase only
- [X] No future phase features are included
- [X] Previous phase is locked before starting this phase

### No Scope Creep Check
- [X] Features belong only to their assigned phase
- [X] No "small additions" from future phases
- [X] No refactors after phase lock

### AI-Friendly Structure Check
- [X] Clear specs before planning
- [X] Clear plans before implementation
- [X] Clear verification before locking

### Deterministic Execution Check
- [X] Every phase produces verifiable outputs
- [X] Ambiguity is resolved in Specify, not Implement

### Mandatory Phase Execution Lifecycle Check
- [X] Follows Specify → Plan → Implement → Verify → Lock sequence
- [X] No phase overlap allowed

### Locked Project Phases Check
- [X] Project phases completed in locked order
- [X] No skipping phases

## User Scenarios & Testing *(mandatory)*

<!--
  IMPORTANT: User stories should be PRIORITIZED as user journeys ordered by importance.
  Each user story/journey must be INDEPENDENTLY TESTABLE - meaning if you implement just ONE of them,
  you should still have a viable MVP (Minimum Viable Product) that delivers value.

  Assign priorities (P1, P2, P3, etc.) to each story, where P1 is the most critical.
  Think of each story as a standalone slice of functionality that can be:
  - Developed independently
  - Tested independently
  - Deployed independently
  - Demonstrated to users independently
-->

### User Story 1 - Chatbot Interaction (Priority: P1)

A student wants to ask questions about the Physical AI & Humanoid Robotics book content and receive accurate answers based on the book's information.

**Why this priority**: This is the core functionality of the chatbot - users need to be able to ask questions and receive relevant answers from the book content.

**Independent Test**: Can be fully tested by verifying users can ask questions and receive accurate answers that are grounded in the book content.

**Acceptance Scenarios**:

1. **Given** a user has opened the chatbot interface, **When** they type a question related to the book content, **Then** they should receive an accurate answer based on the book content.
2. **Given** a user has asked a question, **When** the answer is not found in the book, **Then** they should receive the response "This information is not available in the book."

---

### User Story 2 - Context Selection Mode (Priority: P1)

A student wants to ask questions about specific text they have selected in the book and receive answers only based on that selected text.

**Why this priority**: This provides a more focused way to interact with the content, allowing users to get answers specifically related to what they're reading.

**Independent Test**: Can be fully tested by verifying users can select text and ask questions that are answered only from the selected content.

**Acceptance Scenarios**:

1. **Given** a user has selected text in the book, **When** they ask a question using selection mode, **Then** they should receive an answer based only on the selected text.
2. **Given** a user has selected text that doesn't contain the answer to their question, **When** they ask a question using selection mode, **Then** they should receive the response "This information is not available in the book."

---

### User Story 3 - Chatbot UI Integration (Priority: P2)

A student wants to access the chatbot easily while reading the book without disrupting their reading experience.

**Why this priority**: The chatbot needs to be seamlessly integrated into the book interface to provide a good user experience.

**Independent Test**: Can be fully tested by verifying the chatbot icon is visible, animated, and the chat panel opens without disrupting the reading experience.

**Acceptance Scenarios**:

1. **Given** a user is reading the book, **When** they see the animated chatbot icon, **Then** they should be able to click it to open the chat interface.
2. **Given** a user has opened the chat interface, **When** they interact with it, **Then** it should not disrupt their reading experience of the book content.

---

[Add more user stories as needed, each with an assigned priority]

### Edge Cases

<!--
  ACTION REQUIRED: The content in this section represents placeholders.
  Fill them out with the right edge cases.
-->

- What happens when a user submits a query that is too ambiguous to match relevant content?
- How does the system handle very long user queries?
- What happens when the Ollama service is temporarily unavailable?

## Requirements *(mandatory)*

<!--
  ACTION REQUIRED: The content in this section represents placeholders.
  Fill them out with the right functional requirements.
-->

### Functional Requirements

- **FR-001**: System MUST provide an embedded chatbot UI inside the Physical AI & Humanoid Robotics book
- **FR-002**: System MUST display a floating chatbot icon that is robot-themed and animated
- **FR-003**: System MUST allow users to ask questions about the book content
- **FR-004**: System MUST retrieve relevant book content using a RAG (Retrieval-Augmented Generation) architecture
- **FR-005**: System MUST store document embeddings in Qdrant Cloud vector store
- **FR-006**: System MUST store document metadata in Neon Serverless PostgreSQL
- **FR-007**: System MUST use FastAPI for the backend API
- **FR-008**: System MUST use Ollama as the LLM provider for answer generation
- **FR-009**: System MUST ensure answers are grounded in retrieved documents with no hallucinations
- **FR-010**: System MUST provide two chat modes: Global Mode (full book context) and Selection Mode (selected text only)
- **FR-011**: System MUST hard-fail and respond with "This information is not available in the book" when answer is not found in Selection Mode
- **FR-012**: System MUST chunk and embed book content deterministically
- **FR-013**: System MUST match the Neon robotic theme and Phase 1 UI consistency
- **FR-014**: System MUST load API keys via environment variables
- **FR-015**: System MUST not allow external web access for answer generation

*Example of marking unclear requirements:*

- **FR-016**: System MUST define supported Ollama models (e.g., llama3, mistral, gemma)

### Key Entities *(include if feature involves data)*

- **ChatQuery**: A user's question submitted to the chatbot system - Contains: question text, context mode (global/selection), selected text (if applicable), user session info
- **DocumentChunk**: A segment of book content that has been processed for vector storage - Contains: content text, metadata (source file, section, page), embedding vector, document reference ID
- **VectorEmbedding**: Numerical representation of document content for similarity matching - Contains: embedding vector, associated document chunk ID, metadata for retrieval
- **ChatResponse**: The system's answer to a user's query - Contains: answer text, source references, confidence level, retrieval metadata
- **DocumentMetadata**: Information about book content stored in the database - Contains: document ID, source file path, section/chapter info, creation date, content hash
- **ChatSession**: A user's interaction session with the chatbot - Contains: session ID, user queries history, responses history, context settings

## Success Criteria *(mandatory)*

<!--
  ACTION REQUIRED: Define measurable success criteria.
  These must be technology-agnostic and measurable.
-->

### Measurable Outcomes

- **SC-001**: Chatbot is visible and usable inside the book interface
- **SC-002**: Answers come only from indexed book content with no hallucinations
- **SC-003**: Selection-only answering mode works correctly and hard-fails when answer is not found
- **SC-004**: UI animations function smoothly and match the Neon robotic theme
- **SC-005**: Backend RAG pipeline is stable and responds to queries within acceptable timeframes
- **SC-006**: Phase passes verification and can be locked without constitution violations
- **SC-007**: All required deliverables are completed (Chatbot UI component, FastAPI RAG backend, Qdrant vector index, Neon metadata schema)